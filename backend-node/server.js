const express = require('express');
const cors = require('cors');
const dotenv = require('dotenv');
const OpenAI = require('openai');
const { GoogleGenerativeAI } = require('@google/generative-ai');

dotenv.config();

const app = express();
const PORT = process.env.PORT || 3001;

// Middleware
app.use(cors());
app.use(express.json());

// OpenAI Configuration
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

// Google Gemini Configuration
const genAI = process.env.GOOGLE_API_KEY ? new GoogleGenerativeAI(process.env.GOOGLE_API_KEY) : null;

// Health check endpoint
app.get('/health', (req, res) => {
  res.json({
    status: 'ok',
    service: 'Node.js + AI (OpenAI & Google Gemini)',
    providers: {
      openai: !!process.env.OPENAI_API_KEY,
      google: !!process.env.GOOGLE_API_KEY
    }
  });
});

// AI Generation endpoint
app.post('/api/generate', async (req, res) => {
  try {
    const { studentName, subject, recordType, evidence, templateType, provider = 'google' } = req.body;

    // Validate required fields
    if (!studentName || !recordType || !evidence) {
      return res.status(400).json({
        error: 'Missing required fields: studentName, recordType, evidence'
      });
    }

    // Build prompt based on record type
    const prompts = {
      subject: `ë‹¤ìŒ í•™ìƒì˜ êµê³¼ ì„¸ë¶€ëŠ¥ë ¥íŠ¹ê¸°ì‚¬í•­(ì„¸íŠ¹)ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

í•™ìƒ: ${studentName}
ê³¼ëª©: ${subject || 'í•´ë‹¹ ê³¼ëª©'}
ê·¼ê±° ìë£Œ:
${evidence}

ì‘ì„± ê·œì¹™:
- 200-500ì ë¶„ëŸ‰ìœ¼ë¡œ ì‘ì„±
- êµ¬ì²´ì ì¸ í™œë™ ë‚´ìš©ê³¼ ì„±ì·¨ë¥¼ ê¸°ë¡
- í•™ìƒì˜ ê°•ì ê³¼ íŠ¹ì§•ì„ ê°ê´€ì ìœ¼ë¡œ ì„œìˆ 
- ê¸ˆì¹™ì–´ ì‚¬ìš© ê¸ˆì§€ (ìš°ìˆ˜í•˜ë‹¤, ë›°ì–´ë‚˜ë‹¤, 1ë“± ë“±)
- NEIS ì—…ë¡œë“œ ê°€ëŠ¥í•œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±`,

      activity: `ë‹¤ìŒ í•™ìƒì˜ ì°½ì˜ì  ì²´í—˜í™œë™ ê¸°ë¡ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

í•™ìƒ: ${studentName}
ê·¼ê±° ìë£Œ:
${evidence}

ì‘ì„± ê·œì¹™:
- 100-300ì ë¶„ëŸ‰ìœ¼ë¡œ ì‘ì„±
- í™œë™ì˜ êµ¬ì²´ì ì¸ ê³¼ì •ê³¼ ê²°ê³¼ë¥¼ ê¸°ë¡
- í•™ìƒì˜ ì°¸ì—¬ë„ì™€ íƒœë„ë¥¼ ê°ê´€ì ìœ¼ë¡œ ì„œìˆ 
- ê¸ˆì¹™ì–´ ì‚¬ìš© ê¸ˆì§€`,

      homeroom: `ë‹¤ìŒ í•™ìƒì˜ ë‹´ì„ì¢…í•©ì˜ê²¬ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

í•™ìƒ: ${studentName}
ê·¼ê±° ìë£Œ:
${evidence}

ì‘ì„± ê·œì¹™:
- 300-700ì ë¶„ëŸ‰ìœ¼ë¡œ ì‘ì„±
- í•™ìƒì˜ ì „ë°˜ì ì¸ í•™êµìƒí™œì„ ì¢…í•©ì ìœ¼ë¡œ ê¸°ìˆ 
- ì„±ì¥ ê³¼ì •ê³¼ ë³€í™”ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ê¸°ë¡
- ê¸ì •ì ì´ê³  ê²©ë ¤í•˜ëŠ” í†¤ìœ¼ë¡œ ì‘ì„±
- ê¸ˆì¹™ì–´ ì‚¬ìš© ê¸ˆì§€`,

      career: `ë‹¤ìŒ í•™ìƒì˜ ì§„ë¡œí™œë™ ê¸°ë¡ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

í•™ìƒ: ${studentName}
ê·¼ê±° ìë£Œ:
${evidence}

ì‘ì„± ê·œì¹™:
- 200-400ì ë¶„ëŸ‰ìœ¼ë¡œ ì‘ì„±
- ì§„ë¡œ íƒìƒ‰ í™œë™ê³¼ ê´€ì‹¬ ë¶„ì•¼ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ê¸°ë¡
- í•™ìƒì˜ ì§„ë¡œ ê³„íšê³¼ ì¤€ë¹„ ê³¼ì •ì„ ì„œìˆ 
- ê¸ˆì¹™ì–´ ì‚¬ìš© ê¸ˆì§€`
    };

    const prompt = prompts[recordType] || prompts.subject;
    const systemMessage = "ë‹¹ì‹ ì€ í•œêµ­ì˜ ìƒí™œê¸°ë¡ë¶€(ìƒê¸°ë¶€) ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. NEIS ì‹œìŠ¤í…œì— ì—…ë¡œë“œ ê°€ëŠ¥í•œ í˜•ì‹ìœ¼ë¡œ ì •í™•í•˜ê³  ê°ê´€ì ì¸ ê¸°ë¡ì„ ì‘ì„±í•©ë‹ˆë‹¤. ê¸ˆì¹™ì–´ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©°, êµ¬ì²´ì ì´ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‚´ìš©ì„ ì‘ì„±í•©ë‹ˆë‹¤.";

    let generatedText;
    let modelUsed;

    // Choose provider
    if (provider === 'google' && genAI) {
      // Use Google Gemini
      const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash-exp" });
      const result = await model.generateContent(`${systemMessage}\n\n${prompt}`);
      const response = await result.response;
      generatedText = response.text();
      modelUsed = 'gemini-2.0-flash-exp';
    } else if (provider === 'openai' || !genAI) {
      // Use OpenAI (fallback if Google not available)
      const completion = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [
          { role: "system", content: systemMessage },
          { role: "user", content: prompt }
        ],
        temperature: 0.7,
        max_tokens: 1000
      });
      generatedText = completion.choices[0].message.content;
      modelUsed = 'gpt-4o-mini';
    } else {
      return res.status(503).json({
        error: 'No AI provider available',
        message: 'Please set GOOGLE_API_KEY or OPENAI_API_KEY in .env file'
      });
    }

    // Check for forbidden words
    const forbiddenWords = ['ìš°ìˆ˜í•˜ë‹¤', 'ë›°ì–´ë‚˜ë‹¤', '1ë“±', '2ë“±', 'ê¼´ì°Œ', 'ADHD', 'ADD'];
    const foundForbidden = forbiddenWords.filter(word => generatedText.includes(word));

    res.json({
      success: true,
      generatedText,
      warnings: foundForbidden.length > 0 ? {
        forbiddenWords: foundForbidden,
        message: 'ê¸ˆì¹™ì–´ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.'
      } : null,
      metadata: {
        length: generatedText.replace(/\s/g, '').length,
        model: modelUsed,
        provider: provider === 'google' && genAI ? 'google' : 'openai',
        backend: 'Node.js + Multi-AI'
      }
    });

  } catch (error) {
    console.error('Error generating text:', error);
    res.status(500).json({
      error: 'Failed to generate text',
      message: error.message
    });
  }
});

// Batch generation endpoint
app.post('/api/generate/batch', async (req, res) => {
  try {
    const { students } = req.body;

    if (!Array.isArray(students) || students.length === 0) {
      return res.status(400).json({ error: 'Invalid students array' });
    }

    const results = await Promise.all(
      students.map(async (student) => {
        try {
          const prompt = `${student.studentName} í•™ìƒì˜ ${student.recordType} ê¸°ë¡ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\nê·¼ê±°: ${student.evidence}`;

          const completion = await openai.chat.completions.create({
            model: "gpt-4o-mini",
            messages: [
              { role: "system", content: "ìƒí™œê¸°ë¡ë¶€ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤." },
              { role: "user", content: prompt }
            ],
            temperature: 0.7,
            max_tokens: 800
          });

          return {
            studentName: student.studentName,
            success: true,
            generatedText: completion.choices[0].message.content
          };
        } catch (error) {
          return {
            studentName: student.studentName,
            success: false,
            error: error.message
          };
        }
      })
    );

    res.json({
      success: true,
      results,
      total: students.length,
      successful: results.filter(r => r.success).length
    });

  } catch (error) {
    console.error('Error in batch generation:', error);
    res.status(500).json({ error: 'Batch generation failed', message: error.message });
  }
});

app.listen(PORT, () => {
  console.log(`ğŸš€ Node.js + OpenAI backend running on http://localhost:${PORT}`);
  console.log(`ğŸ“ Endpoint: POST http://localhost:${PORT}/api/generate`);
});
